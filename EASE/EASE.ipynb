{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EASE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1C1AHkN-z-DCxUIAjFfd7K56P-8-YrAJO",
      "authorship_tag": "ABX9TyMoF11Uk2GPLa5U/j8sZ0UD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongBeomLEE/RecsysTutorial/blob/main/EASE/EASE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-box"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzJgxsrewLBy",
        "outputId": "5391026c-afb2-4612-8413-3c0219f2727d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-box in /usr/local/lib/python3.7/dist-packages (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ug-br-pPu9vZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from box import Box\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "torch.set_printoptions(sci_mode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbRKDSg4u9vc"
      },
      "source": [
        "# 1. 학습 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MEhK_fLIu9vd"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'data_path' : \"/content/drive/MyDrive/RecsysTutorial/Data/MovieLens\" , # 데이터 경로\n",
        "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
        "    'seed' : 22,\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = Box(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjDxy0fJu9vf"
      },
      "source": [
        "# 2. 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W64BYWl0u9vg"
      },
      "outputs": [],
      "source": [
        "class MakeMatrixDataSet():\n",
        "    \"\"\"\n",
        "    MatrixDataSet 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'ratings.csv'))\n",
        "        \n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('movieId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['movieId'].apply(lambda x : self.item_encoder[x])\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "\n",
        "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
        "\n",
        "    def generate_encoder_decoder(self, col : str) -> dict:\n",
        "        \"\"\"\n",
        "        encoder, decoder 생성\n",
        "\n",
        "        Args:\n",
        "            col (str): 생성할 columns 명\n",
        "        Returns:\n",
        "            dict: 생성된 user encoder, decoder\n",
        "        \"\"\"\n",
        "\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "\n",
        "        return encoder, decoder\n",
        "    \n",
        "    def generate_sequence_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        sequence_data 생성\n",
        "\n",
        "        Returns:\n",
        "            dict: train user sequence / valid user sequence\n",
        "        \"\"\"\n",
        "        users = defaultdict(list)\n",
        "        user_train = {}\n",
        "        user_valid = {}\n",
        "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['timestamp']):\n",
        "            users[user].append(item)\n",
        "        \n",
        "        for user in users:\n",
        "            np.random.seed(self.config.seed)\n",
        "\n",
        "            user_total = users[user]\n",
        "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
        "            train = list(set(user_total) - set(valid))\n",
        "\n",
        "            user_train[user] = train\n",
        "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
        "\n",
        "        return user_train, user_valid\n",
        "    \n",
        "    def get_train_valid_data(self):\n",
        "        return self.user_train, self.user_valid\n",
        "\n",
        "    def make_matrix(self, user_list, train = True):\n",
        "        \"\"\"\n",
        "        user_item_dict를 바탕으로 행렬 생성\n",
        "        \"\"\"\n",
        "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
        "        for idx, user in enumerate(user_list):\n",
        "            if train:\n",
        "                mat[idx, self.user_train[user.item()]] = 1\n",
        "            else:\n",
        "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
        "        return mat\n",
        "\n",
        "    def make_sparse_matrix(self):\n",
        "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
        "        for user in self.user_train.keys():\n",
        "            item_list = self.user_train[user]\n",
        "            X[user, item_list] = 1.0\n",
        "                \n",
        "        return X.tocsr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IldCGmY8u9vh"
      },
      "outputs": [],
      "source": [
        "class AEDataSet(Dataset):\n",
        "    def __init__(self, num_user):\n",
        "        self.num_user = num_user\n",
        "        self.users = [i for i in range(num_user)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_user\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        user = self.users[idx]\n",
        "        return torch.LongTensor([user])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysia457Su9vi"
      },
      "source": [
        "# 3. 모델"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EASE():\n",
        "    def __init__(self, X, reg):\n",
        "        self.X = self._convert_sp_mat_to_sp_tensor(X)\n",
        "        self.reg = reg\n",
        "    \n",
        "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
        "        \"\"\"\n",
        "        Convert scipy sparse matrix to PyTorch sparse matrix\n",
        "\n",
        "        Arguments:\n",
        "        ----------\n",
        "        X = Adjacency matrix, scipy sparse matrix\n",
        "        \"\"\"\n",
        "        coo = X.tocoo().astype(np.float32)\n",
        "        i = torch.LongTensor(np.mat([coo.row, coo.col]))\n",
        "        v = torch.FloatTensor(coo.data)\n",
        "        res = torch.sparse.FloatTensor(i, v, coo.shape).to(device)\n",
        "        return res\n",
        "    \n",
        "    def fit(self):\n",
        "        '''\n",
        "\n",
        "        진짜 정말 간단한 식으로 모델을 만듬\n",
        "\n",
        "        '''\n",
        "        G = self.X.to_dense().t() @ self.X.to_dense()\n",
        "        diagIndices = torch.eye(G.shape[0]) == 1\n",
        "        G[diagIndices] += self.reg\n",
        "\n",
        "        P = G.inverse()\n",
        "        B = P / (-1 * P.diag())\n",
        "        B[diagIndices] = 0\n",
        "\n",
        "        self.pred = self.X.to_dense() @ B"
      ],
      "metadata": {
        "id": "TVXWUTLpSh8_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwSexh43u9vk"
      },
      "source": [
        "# 4. 학습 함수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ndcg(pred_list, true_list):\n",
        "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
        "    dcg = 0\n",
        "    for rank, pred in enumerate(pred_list):\n",
        "        if pred in true_list:\n",
        "            dcg += 1 / np.log2(rank + 2)\n",
        "    ndcg = dcg / idcg\n",
        "    return ndcg\n",
        "\n",
        "# hit == recall == precision\n",
        "def get_hit(pred_list, true_list):\n",
        "    hit_list = set(true_list) & set(pred_list)\n",
        "    hit = len(hit_list) / len(true_list)\n",
        "    return hit\n",
        "\n",
        "def evaluate(model, X, user_train, user_valid):\n",
        "\n",
        "    mat = torch.from_numpy(X)\n",
        "\n",
        "    NDCG = 0.0 # NDCG@10\n",
        "    HIT = 0.0 # HIT@10\n",
        "\n",
        "    recon_mat1 = model.pred.cpu()\n",
        "    recon_mat1[mat == 1] = -np.inf\n",
        "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
        "\n",
        "    for user, rec1 in tqdm(enumerate(rec_list1)):\n",
        "        uv = user_valid[user]\n",
        "\n",
        "        # ranking\n",
        "        up = rec1[-10:].cpu().numpy().tolist()[::-1]\n",
        "\n",
        "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
        "        HIT += get_hit(pred_list = up, true_list = uv)\n",
        "\n",
        "    NDCG /= len(user_train)\n",
        "    HIT /= len(user_train)\n",
        "\n",
        "    return NDCG, HIT"
      ],
      "metadata": {
        "id": "nws4JO2_rgQP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 학습"
      ],
      "metadata": {
        "id": "gupkaJHMslCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
        "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
        "X = make_matrix_data_set.make_sparse_matrix()"
      ],
      "metadata": {
        "id": "HFOr6Wmbq9pW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for reg in [1000, 100, 10, 1, 0.1, 0.01]:\n",
        "    model = EASE(X = X, reg = reg)\n",
        "    model.fit()\n",
        "    ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n",
        "    print(f'reg: {reg}| NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
      ],
      "metadata": {
        "id": "mzhvIGPhrYov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8678797c-2c8c-4d80-856f-e1dbd9296391"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reg: 1000| NDCG@10: 0.25119| HIT@10: 0.16632\n",
            "reg: 100| NDCG@10: 0.25478| HIT@10: 0.17034\n",
            "reg: 10| NDCG@10: 0.21501| HIT@10: 0.14665\n",
            "reg: 1| NDCG@10: 0.17204| HIT@10: 0.11952\n",
            "reg: 0.1| NDCG@10: 0.15148| HIT@10: 0.10820\n",
            "reg: 0.01| NDCG@10: 0.14013| HIT@10: 0.10060\n"
          ]
        }
      ]
    }
  ]
}