{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EASER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18cN7V4h9V6Tw6er-0McS5EcMwJQwY_yJ",
      "authorship_tag": "ABX9TyNYBdBa3vxWd0KYmI9cpjt+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongBeomLEE/RecsysTutorial/blob/main/EASER/EASER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-box"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzJgxsrewLBy",
        "outputId": "92496818-af87-40d1-f5ec-136a5caa7bfa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-box in /usr/local/lib/python3.7/dist-packages (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ug-br-pPu9vZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from box import Box\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "torch.set_printoptions(sci_mode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbRKDSg4u9vc"
      },
      "source": [
        "# 1. 학습 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MEhK_fLIu9vd"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'data_path' : \"/content/drive/MyDrive/RecsysTutorial/Data/MovieLens\" , # 데이터 경로\n",
        "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
        "    'seed' : 22,\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = Box(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjDxy0fJu9vf"
      },
      "source": [
        "# 2. 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W64BYWl0u9vg"
      },
      "outputs": [],
      "source": [
        "class MakeMatrixDataSet():\n",
        "    \"\"\"\n",
        "    MatrixDataSet 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'ratings.csv'))\n",
        "        \n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('movieId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['movieId'].apply(lambda x : self.item_encoder[x])\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "\n",
        "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
        "\n",
        "    def generate_encoder_decoder(self, col : str) -> dict:\n",
        "        \"\"\"\n",
        "        encoder, decoder 생성\n",
        "\n",
        "        Args:\n",
        "            col (str): 생성할 columns 명\n",
        "        Returns:\n",
        "            dict: 생성된 user encoder, decoder\n",
        "        \"\"\"\n",
        "\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "\n",
        "        return encoder, decoder\n",
        "    \n",
        "    def generate_sequence_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        sequence_data 생성\n",
        "\n",
        "        Returns:\n",
        "            dict: train user sequence / valid user sequence\n",
        "        \"\"\"\n",
        "        users = defaultdict(list)\n",
        "        user_train = {}\n",
        "        user_valid = {}\n",
        "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['timestamp']):\n",
        "            users[user].append(item)\n",
        "        \n",
        "        for user in users:\n",
        "            np.random.seed(self.config.seed)\n",
        "\n",
        "            user_total = users[user]\n",
        "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
        "            train = list(set(user_total) - set(valid))\n",
        "\n",
        "            user_train[user] = train\n",
        "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
        "\n",
        "        return user_train, user_valid\n",
        "    \n",
        "    def get_train_valid_data(self):\n",
        "        return self.user_train, self.user_valid\n",
        "\n",
        "    def make_matrix(self, user_list, train = True):\n",
        "        \"\"\"\n",
        "        user_item_dict를 바탕으로 행렬 생성\n",
        "        \"\"\"\n",
        "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
        "        for idx, user in enumerate(user_list):\n",
        "            if train:\n",
        "                mat[idx, self.user_train[user.item()]] = 1\n",
        "            else:\n",
        "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
        "        return mat\n",
        "\n",
        "    def make_sparse_matrix(self):\n",
        "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
        "        for user in self.user_train.keys():\n",
        "            item_list = self.user_train[user]\n",
        "            X[user, item_list] = 1.0\n",
        "                \n",
        "        return X.tocsr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IldCGmY8u9vh"
      },
      "outputs": [],
      "source": [
        "class AEDataSet(Dataset):\n",
        "    def __init__(self, num_user):\n",
        "        self.num_user = num_user\n",
        "        self.users = [i for i in range(num_user)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_user\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        user = self.users[idx]\n",
        "        return torch.LongTensor([user])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysia457Su9vi"
      },
      "source": [
        "# 3. 모델"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from copy import deepcopy\n",
        "\n",
        "class EASER():\n",
        "    def __init__(self, threshold = 3500, lambdaBB = 500, lambdaCC = 10000, rho = 50000, epochs = 40):\n",
        "        self.threshold = threshold\n",
        "        self.lambdaBB = lambdaBB\n",
        "        self.lambdaCC = lambdaCC\n",
        "        self.rho = rho\n",
        "        self.epochs = epochs\n",
        "    \n",
        "    def create_list_feature_pairs(self, XtX):\n",
        "        AA = np.triu(np.abs(XtX))\n",
        "        AA[ np.diag_indices(AA.shape[0]) ]=0.0\n",
        "        ii_pairs = np.where((AA > self.threshold) == True)\n",
        "        return ii_pairs\n",
        "    \n",
        "    def create_matrix_Z(self, ii_pairs, X):\n",
        "        MM = np.zeros( (len(ii_pairs[0]), X.shape[1]),    dtype=np.float64)\n",
        "        MM[np.arange(MM.shape[0]) , ii_pairs[0]   ]=1.0\n",
        "        MM[np.arange(MM.shape[0]) , ii_pairs[1]   ]=1.0\n",
        "        CCmask = 1.0-MM\n",
        "        MM = sparse.csc_matrix(MM.T)\n",
        "        Z=  X * MM\n",
        "        Z= (Z == 2.0 )\n",
        "        Z=Z*1.0\n",
        "        return Z, CCmask\n",
        "\n",
        "    def train_higher(self, XtX, XtXdiag, ZtZ, ZtZdiag, CCmask, ZtX):\n",
        "        ii_diag=np.diag_indices(XtX.shape[0])\n",
        "        XtX[ii_diag] = XtXdiag + self.lambdaBB\n",
        "        PP = np.linalg.inv(XtX)\n",
        "        ii_diag_ZZ=np.diag_indices(ZtZ.shape[0])\n",
        "        ZtZ[ii_diag_ZZ] = ZtZdiag + self.lambdaCC + self.rho\n",
        "        QQ=np.linalg.inv(ZtZ)\n",
        "        CC = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float64 )\n",
        "        DD = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float64 )\n",
        "        UU = np.zeros( (ZtZ.shape[0], XtX.shape[0]),dtype=np.float64 )\n",
        "\n",
        "        for iter in range(self.epochs):\n",
        "            # learn BB\n",
        "            XtX[ii_diag] = XtXdiag\n",
        "            BB= PP.dot(XtX-ZtX.T.dot(CC))\n",
        "            gamma = np.diag(BB) / np.diag(PP)\n",
        "            BB-= PP * gamma\n",
        "            # learn CC\n",
        "            CC= QQ.dot(ZtX-ZtX.dot(BB) + self.rho * (DD-UU))\n",
        "            # learn DD\n",
        "            DD=  CC  * CCmask \n",
        "            #DD= np.maximum(0.0, DD) # if you want to enforce non-negative parameters\n",
        "            # learn UU (is Gamma in paper)\n",
        "            UU+= CC-DD\n",
        "        \n",
        "        return BB, DD\n",
        "\n",
        "    def fit(self, X):\n",
        "        print(' --- init')\n",
        "        XtX = (X.transpose() * X).toarray()\n",
        "        XtXdiag = deepcopy(np.diag(XtX))\n",
        "        ii_pairs = self.create_list_feature_pairs(XtX)\n",
        "        Z, CCmask = self.create_matrix_Z(ii_pairs, X)\n",
        "\n",
        "        ZtZ = (Z.transpose() * Z).toarray()\n",
        "        ZtZdiag = deepcopy(np.diag(ZtZ))\n",
        "\n",
        "        ZtX = (Z.transpose() * X).toarray()\n",
        "        \n",
        "        print(' --- iteration start.')\n",
        "        BB, CC = self.train_higher(XtX, XtXdiag, ZtZ, ZtZdiag, CCmask, ZtX)\n",
        "        print(' --- iteration end.')\n",
        "\n",
        "        self.pred = torch.from_numpy(X.toarray().dot(BB) + Z.toarray().dot(CC))"
      ],
      "metadata": {
        "id": "TVXWUTLpSh8_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwSexh43u9vk"
      },
      "source": [
        "# 4. 학습 함수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ndcg(pred_list, true_list):\n",
        "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
        "    dcg = 0\n",
        "    for rank, pred in enumerate(pred_list):\n",
        "        if pred in true_list:\n",
        "            dcg += 1 / np.log2(rank + 2)\n",
        "    ndcg = dcg / idcg\n",
        "    return ndcg\n",
        "\n",
        "# hit == recall == precision\n",
        "def get_hit(pred_list, true_list):\n",
        "    hit_list = set(true_list) & set(pred_list)\n",
        "    hit = len(hit_list) / len(true_list)\n",
        "    return hit\n",
        "\n",
        "def evaluate(model, X, user_train, user_valid):\n",
        "\n",
        "    mat = torch.from_numpy(X)\n",
        "\n",
        "    NDCG = 0.0 # NDCG@10\n",
        "    HIT = 0.0 # HIT@10\n",
        "\n",
        "    recon_mat1 = model.pred.cpu()\n",
        "    recon_mat1[mat == 1] = -np.inf\n",
        "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
        "\n",
        "    for user, rec1 in tqdm(enumerate(rec_list1)):\n",
        "        uv = user_valid[user]\n",
        "\n",
        "        # ranking\n",
        "        up = rec1[-10:].cpu().numpy().tolist()[::-1]\n",
        "\n",
        "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
        "        HIT += get_hit(pred_list = up, true_list = uv)\n",
        "\n",
        "    NDCG /= len(user_train)\n",
        "    HIT /= len(user_train)\n",
        "\n",
        "    return NDCG, HIT"
      ],
      "metadata": {
        "id": "nws4JO2_rgQP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 학습"
      ],
      "metadata": {
        "id": "gupkaJHMslCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
        "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
        "X = make_matrix_data_set.make_sparse_matrix()"
      ],
      "metadata": {
        "id": "HFOr6Wmbq9pW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = EASER(epochs = 10)\n",
        "model.fit(X = X)\n",
        "ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n",
        "print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
      ],
      "metadata": {
        "id": "mzhvIGPhrYov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27021501-89f4-4247-bf45-2598b7302fad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --- init\n",
            " --- iteration start.\n",
            " --- iteration end.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "671it [00:00, 12419.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG@10: 0.25998| HIT@10: 0.17243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}