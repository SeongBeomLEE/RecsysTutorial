{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Caser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ceMmry3vE4z5TNTcsy21pH1rvHcbsllP",
      "authorship_tag": "ABX9TyPqgf0Ox+/D9JAO2VpV8Rog",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongBeomLEE/RecsysTutorial/blob/main/Caser/Caser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-box"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pw7yHQGiz3q",
        "outputId": "c5880330-70c8-4233-dfdc-008416198a50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-box\n",
            "  Downloading python_box-5.4.1-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: python-box\n",
            "Successfully installed python-box-5.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L3pG4yjI38Q0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from box import Box\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/RecsysTutorial/Data/MovieLens/'\n",
        "model_dir = '/content/drive/MyDrive/RecsysTutorial/Model/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 설정은 최대한 오피셜 깃허브 코드와 동일하게 함\n",
        "# l2 norm은 적용하지 않음\n",
        "config = {\n",
        "    'k' : 30,\n",
        "    'epochs' : 50,\n",
        "    'lr' : 1e-03,\n",
        "    'batch_size' : 512,\n",
        "    'device' : torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),\n",
        "\n",
        "    'L' : 5,\n",
        "    'T' : 3,\n",
        "    'd' : 50,\n",
        "    'nv' : 4,\n",
        "    'nh' :16,\n",
        "    'drop_ratio' : 0.5,\n",
        "    'neg_samples' : 3,\n",
        "}\n",
        "\n",
        "config = Box(config)"
      ],
      "metadata": {
        "id": "HdKE3CLEi-XQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 확인"
      ],
      "metadata": {
        "id": "dLHonyUm5x51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df = pd.read_csv(data_dir + 'ratings.csv')\n",
        "ratings_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "xHXEweQq5Xfu",
        "outputId": "431d4f57-f988-4294-d07d-807ac5fb9477"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1       31     2.5  1260759144\n",
              "1       1     1029     3.0  1260759179\n",
              "2       1     1061     3.0  1260759182\n",
              "3       1     1129     2.0  1260759185\n",
              "4       1     1172     4.0  1260759205\n",
              "5       1     1263     2.0  1260759151\n",
              "6       1     1287     2.0  1260759187\n",
              "7       1     1293     2.0  1260759148\n",
              "8       1     1339     3.5  1260759125\n",
              "9       1     1343     2.0  1260759131"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2162401-4158-46f8-8c62-8869492813b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1260759144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1029</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1260759179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1061</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1260759182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1129</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1172</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1260759205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1263</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1287</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1293</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1339</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1260759125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1343</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2162401-4158-46f8-8c62-8869492813b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2162401-4158-46f8-8c62-8869492813b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2162401-4158-46f8-8c62-8869492813b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = ratings_df['userId'].nunique()\n",
        "num_items = ratings_df['movieId'].nunique()\n",
        "\n",
        "sparsity = 1 - len(ratings_df) / (num_users * num_items)\n",
        "\n",
        "print(f'전체 User 수: {num_users}')\n",
        "print(f'전체 Item 수: {num_items}')\n",
        "print(f'행렬의 희소성: {sparsity:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KKZeIWg6iSp",
        "outputId": "6621cc98-3b14-4831-b92d-4b00b2d3816c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 User 수: 671\n",
            "전체 Item 수: 9066\n",
            "행렬의 희소성: 0.9836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataSet"
      ],
      "metadata": {
        "id": "nfr9ZtE35ze_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MakeDataset():\n",
        "    def __init__(self, config, df : pd.DataFrame):\n",
        "        self.config = config\n",
        "        self.df = df\n",
        "        self.user_encoder, self.user_decoder, self.item_encoder, self.item_decoder = self.get_encoder_decoder()\n",
        "        self.num_users = len(self.user_encoder)\n",
        "        self.num_items = len(self.item_encoder)\n",
        "        self.all_items = [i for i in range(self.num_items)]\n",
        "\n",
        "        self.df['userId'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "        self.df['movieId'] = self.df['movieId'].apply(lambda x : self.item_encoder[x])\n",
        "        self.user_neg_candidate = self.get_user_neg_candidate()\n",
        "\n",
        "        self.train_sequence_user, self.train_sequence_L, self.train_sequence_T, self.test_sequence_user, self.test_sequence_L, self.test_sequence_T = self.train_test_data_split()\n",
        "\n",
        "    def train_test_data_split(self):\n",
        "\n",
        "        user_id_li = self.df['userId'].unique()\n",
        "        train_sequence_user = []\n",
        "        test_sequence_user = []\n",
        "\n",
        "        train_sequence_L = []\n",
        "        test_sequence_L = []\n",
        "\n",
        "        train_sequence_T = []\n",
        "        test_sequence_T = []\n",
        "        for user_id in user_id_li:\n",
        "            sequence_user = []\n",
        "            sequence_L = []\n",
        "            sequence_T = []\n",
        "\n",
        "            user_df = self.df[self.df['userId'] == user_id].sort_values('timestamp')\n",
        "            movieId_li = user_df['movieId'].tolist()\n",
        "            seq_length = self.config.T + self.config.L\n",
        "            if len(movieId_li) > seq_length:\n",
        "                for i in range(0, len(movieId_li) - seq_length + 1):\n",
        "                    sequence = movieId_li[i : i + seq_length]\n",
        "                    \n",
        "                    sequence_user.append(user_id)\n",
        "                    sequence_L.append(sequence[ : -self.config.T])\n",
        "                    sequence_T.append(sequence[-self.config.T : ])\n",
        "\n",
        "            train_sequence_user.extend(sequence_user[:-1])\n",
        "            test_sequence_user.extend(sequence_user[-1:])\n",
        "\n",
        "            train_sequence_L.extend(sequence_L[:-1])\n",
        "            test_sequence_L.extend(sequence_L[-1:])\n",
        "\n",
        "            train_sequence_T.extend(sequence_T[:-1])\n",
        "            test_sequence_T.extend(sequence_T[-1:])\n",
        "\n",
        "        return train_sequence_user, train_sequence_L, train_sequence_T, test_sequence_user, test_sequence_L, test_sequence_T\n",
        "\n",
        "    def get_neg_samples(self, n : int, user_id_li):\n",
        "        neg_samples = []\n",
        "        for u in user_id_li:\n",
        "            neg_sample = []\n",
        "            u_neg_candidate = self.user_neg_candidate[u]\n",
        "            for _ in range(n):\n",
        "                neg_sample.append(u_neg_candidate[np.random.randint(len(u_neg_candidate))])\n",
        "            neg_samples.append(neg_sample)\n",
        "\n",
        "        return neg_samples\n",
        "\n",
        "    def get_user_neg_candidate(self):\n",
        "        user_candidate = {}\n",
        "        for user_id in self.df['userId'].unique():\n",
        "            movieId_li = self.df[self.df['userId'] == user_id]['movieId'].tolist()\n",
        "            movieId_li = [movieId for movieId in movieId_li]\n",
        "            user_candidate[user_id] = list(set(self.all_items) - set(movieId_li))\n",
        "        \n",
        "        return user_candidate\n",
        "\n",
        "    def get_encoder_decoder(self):\n",
        "        user_encoder, user_decoder = {}, {}\n",
        "        for idx, user_id in enumerate(self.df['userId'].unique()):\n",
        "            user_encoder[user_id] = idx\n",
        "            user_decoder[idx] = user_id\n",
        "\n",
        "        item_encoder, item_decoder = {}, {}\n",
        "        for idx, item_id in enumerate(self.df['movieId'].unique()):\n",
        "            item_encoder[item_id] = idx\n",
        "            item_decoder[idx] = item_id\n",
        "        \n",
        "        return user_encoder, user_decoder, item_encoder, item_decoder\n",
        "    \n",
        "    def get_data(self, train : bool = True):\n",
        "        if train: return self.train_sequence_user, self.train_sequence_L, self.train_sequence_T\n",
        "        else: return self.test_sequence_user, self.test_sequence_L, self.test_sequence_T"
      ],
      "metadata": {
        "id": "nedmoGy55Xj1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sequence_user : list, sequence_L : list, sequence_T : list):\n",
        "        self.sequence_user = sequence_user\n",
        "        self.sequence_L = sequence_L\n",
        "        self.sequence_T = sequence_T\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequence_user)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence_user = self.sequence_user[idx]\n",
        "        sequence_L = torch.tensor(self.sequence_L[idx])\n",
        "        sequence_T = torch.tensor(self.sequence_T[idx])\n",
        "\n",
        "        return sequence_user, sequence_L, sequence_T"
      ],
      "metadata": {
        "id": "U17QvK7mj3dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델"
      ],
      "metadata": {
        "id": "qL2AqX_g51Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Caser(nn.Module):\n",
        "    def __init__(self, config, num_users : int, num_items : int):\n",
        "        super(Caser, self).__init__()\n",
        "        self.config = config\n",
        "        self.d = self.config.d # 임베딩 차원\n",
        "        self.nv = self.config.nv # vertical conv layer의 필터의 수\n",
        "        self.nh = self.config.nh # horizontal conv layer의 필터의 수\n",
        "        self.drop_ratio = self.config.drop_ratio # dropout 비율\n",
        "\n",
        "\n",
        "        self.P = nn.Embedding(num_users, self.d) # user Embedding\n",
        "        self.Q = nn.Embedding(num_items, self.d) # item Embedding\n",
        "\n",
        "        # vertical conv layer\n",
        "        self.conv_v = nn.Conv2d(in_channels = 1, out_channels = self.nv, kernel_size = (self.config.L, 1))\n",
        "\n",
        "        # horizontal conv layer\n",
        "        lengths = [i + 1 for i in range(self.config.L)]\n",
        "        self.conv_h = nn.ModuleList([nn.Conv2d(in_channels = 1, out_channels = self.nh, kernel_size = (i, self.d)) for i in lengths])\n",
        "\n",
        "        # convolutional sequence embedding\n",
        "        self.conv_v_d = self.nv * self.d\n",
        "        self.conv_h_d = self.nh * self.config.L\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.conv_v_d + self.conv_h_d, self.d),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # output\n",
        "        self.Q_prime = nn.Embedding(num_items, self.d * 2)\n",
        "        self.b = nn.Embedding(num_items, 1)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(self.drop_ratio)\n",
        "\n",
        "    def weight_initialization(self):\n",
        "        self.P.weight.data.normal_(0, 1.0 / self.P.embedding_dim)\n",
        "        self.Q.weight.data.normal_(0, 1.0 / self.Q.embedding_dim)\n",
        "        self.Q_prime.weight.data.normal_(0, 1.0 / self.Q_prime.embedding_dim)\n",
        "        self.b.weight.data.zero_()\n",
        "\n",
        "    def forward(self, user, sequence_L, sequence_T, pred = False):\n",
        "        \n",
        "        #### Embedding Look-up\n",
        "        user_emb = self.P(user)\n",
        "        item_emb = self.Q(sequence_L).unsqueeze(1)\n",
        "\n",
        "        #### Convolutional Layers\n",
        "        # vertical conv layer\n",
        "        out_v = self.conv_v(item_emb).view(-1, self.conv_v_d)\n",
        "\n",
        "        # horizontal conv layer\n",
        "        out_h = []\n",
        "        for conv in self.conv_h:\n",
        "            out = conv(item_emb).squeeze(3)\n",
        "            out = F.max_pool1d(out, out.shape[2]).squeeze(2)\n",
        "            out_h.append(out)\n",
        "        out_h = torch.cat(out_h, 1)\n",
        "\n",
        "        # convolutional sequence embedding\n",
        "        out = torch.cat([out_v, out_h], 1)\n",
        "        out = self.dropout(out)\n",
        "        z = self.fc(out)\n",
        "\n",
        "        ### output\n",
        "        x = torch.cat([z, user_emb], 1)\n",
        "        W = self.Q_prime(sequence_T)\n",
        "        b = self.b(sequence_T)\n",
        "\n",
        "        if pred:\n",
        "            W = W.squeeze()\n",
        "            b = b.squeeze()\n",
        "            res = (x * W).sum(1) + b\n",
        "        else:\n",
        "            res = torch.baddbmm(b, W, x.unsqueeze(2)).squeeze()\n",
        "\n",
        "        return res"
      ],
      "metadata": {
        "id": "DxuOh_Fp53HR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 설정"
      ],
      "metadata": {
        "id": "CCEOTrmjdAgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomLoss, self).__init__()\n",
        "\n",
        "    def forward(self, targets_prediction, negatives_prediction):\n",
        "        positive_loss = -torch.mean(\n",
        "            torch.log(torch.sigmoid(targets_prediction))\n",
        "        )\n",
        "\n",
        "        negative_loss = -torch.mean(\n",
        "            torch.log(1 - torch.sigmoid(negatives_prediction))\n",
        "        )\n",
        "\n",
        "        loss = positive_loss + negative_loss\n",
        "        return loss"
      ],
      "metadata": {
        "id": "blOdvvCZXr39"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recall(target_list, pred_list, k):\n",
        "    cnt = 0\n",
        "    for t in target_list:\n",
        "        if t in pred_list[:k]:\n",
        "            cnt += 1\n",
        "    score = cnt / len(target_list)\n",
        "    return score\n",
        "\n",
        "def get_precision(target_list, pred_list, k):\n",
        "    cnt = 0\n",
        "    for t in target_list:\n",
        "        if t in pred_list[:k]:\n",
        "            cnt += 1\n",
        "    score = cnt / len(pred_list[:k])\n",
        "    return score\n",
        "\n",
        "def get_ap(target_list, pred_list, k):\n",
        "    score = 0\n",
        "    for i in range(1, k + 1):\n",
        "        score += get_precision(target_list, pred_list, k = i)\n",
        "    score /= k\n",
        "    return score"
      ],
      "metadata": {
        "id": "IOhZfjxXYa4U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    loss_val = 0\n",
        "\n",
        "    for i in data_loader:\n",
        "        sequence_user, sequence_L, sequence_T = i\n",
        "        neg_sequence_T = torch.tensor(dataset.get_neg_samples(n = config.neg_samples, user_id_li = sequence_user.numpy()))\n",
        "        b_size = sequence_user.shape[0]\n",
        "\n",
        "        sequence_user = torch.cat([sequence_user, sequence_user], axis = 0).to(config.device)\n",
        "        sequence_L = torch.cat([sequence_L, sequence_L], axis = 0).to(config.device)\n",
        "        sequence_T = torch.cat([sequence_T, neg_sequence_T], axis = 0).to(config.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(sequence_user, sequence_L, sequence_T)\n",
        "\n",
        "        targets_prediction, negatives_prediction = torch.split(output, b_size)\n",
        "\n",
        "        loss = criterion(targets_prediction, negatives_prediction)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_val += loss.item()\n",
        "    \n",
        "    loss_val = loss_val / len(data_loader)\n",
        "\n",
        "    return loss_val\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "\n",
        "    recall = 0\n",
        "    precision = 0\n",
        "    ap = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in data_loader:\n",
        "            sequence_user, sequence_L, sequence_T = i\n",
        "\n",
        "            sequence_user = sequence_user.to(config.device)\n",
        "            sequence_L = sequence_L.to(config.device)\n",
        "            item_list = torch.tensor(dataset.all_items).to(config.device)\n",
        "\n",
        "            pred_list = model(sequence_user, sequence_L, item_list, pred = True).argsort(descending = True).cpu().numpy()\n",
        "            target_list = sequence_T[0].cpu().numpy()\n",
        "\n",
        "            recall += get_recall(target_list, pred_list, k = config.k)\n",
        "            precision += get_precision(target_list, pred_list, k = config.k)\n",
        "            ap += get_ap(target_list, pred_list, k = config.k)\n",
        "\n",
        "    recall = recall / len(data_loader)\n",
        "    precision = precision / len(data_loader)\n",
        "    ap = ap / len(data_loader)\n",
        "\n",
        "    return recall, precision, ap"
      ],
      "metadata": {
        "id": "fzVOhKahZp4R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ],
      "metadata": {
        "id": "iF6B3LdgdEBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MakeDataset(config = config, df = ratings_df)"
      ],
      "metadata": {
        "id": "NXzXIXFoeJ2e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequence_user, train_sequence_L, train_sequence_T = dataset.get_data(train = True)\n",
        "train_dataset = CustomDataset(sequence_user = train_sequence_user, sequence_L = train_sequence_L, sequence_T = train_sequence_T)\n",
        "train_loader = DataLoader(train_dataset, batch_size = config.batch_size, shuffle = True, drop_last = False)\n",
        "\n",
        "test_sequence_user, test_sequence_L, test_sequence_T = dataset.get_data(train = False)\n",
        "test_dataset = CustomDataset(sequence_user = test_sequence_user, sequence_L = test_sequence_L, sequence_T = test_sequence_T)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False, drop_last = False)"
      ],
      "metadata": {
        "id": "ktUwoGKTP72U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Caser(config = config, num_users = dataset.num_users, num_items = dataset.num_items).to(config.device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = config.lr)\n",
        "criterion = CustomLoss()"
      ],
      "metadata": {
        "id": "XjprnFNXeMOF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기화를 해주지 않으면 기울기가 망가져서 모델 학습이 안됨\n",
        "model.weight_initialization()\n",
        "\n",
        "best_metric = 0\n",
        "\n",
        "for epoch in range(1, config.epochs + 1):\n",
        "    train_loss = train(model = model, data_loader = train_loader, criterion = criterion, optimizer = optimizer)\n",
        "    recall, precision, ap = evaluate(model = model, data_loader = test_loader)\n",
        "\n",
        "    print(f\"[EPOCH: {epoch}], Train Loss: {train_loss:.4f}, Recall@{config.k}: {recall:.4f}, Precision@{config.k}: {precision:.4f}, MAP@{config.k}: {ap:.4f},\")\n",
        "\n",
        "    if best_metric < ap:\n",
        "        best_metric = ap\n",
        "        torch.save(model.state_dict(), model_dir + f'Caser.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Q0IMN373Ux",
        "outputId": "7706cf15-d220-4df0-ef6c-4df3f02e8d45"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH: 1], Train Loss: 0.9651, Recall@30: 0.0581, Precision@30: 0.0058, MAP@30: 0.0062,\n",
            "[EPOCH: 2], Train Loss: 0.7882, Recall@30: 0.0631, Precision@30: 0.0063, MAP@30: 0.0071,\n",
            "[EPOCH: 3], Train Loss: 0.6682, Recall@30: 0.0631, Precision@30: 0.0063, MAP@30: 0.0074,\n",
            "[EPOCH: 4], Train Loss: 0.5769, Recall@30: 0.0720, Precision@30: 0.0072, MAP@30: 0.0074,\n",
            "[EPOCH: 5], Train Loss: 0.5096, Recall@30: 0.0765, Precision@30: 0.0077, MAP@30: 0.0074,\n",
            "[EPOCH: 6], Train Loss: 0.4602, Recall@30: 0.0725, Precision@30: 0.0073, MAP@30: 0.0076,\n",
            "[EPOCH: 7], Train Loss: 0.4153, Recall@30: 0.0735, Precision@30: 0.0074, MAP@30: 0.0074,\n",
            "[EPOCH: 8], Train Loss: 0.3818, Recall@30: 0.0914, Precision@30: 0.0091, MAP@30: 0.0082,\n",
            "[EPOCH: 9], Train Loss: 0.3537, Recall@30: 0.0720, Precision@30: 0.0072, MAP@30: 0.0074,\n",
            "[EPOCH: 10], Train Loss: 0.3300, Recall@30: 0.0805, Precision@30: 0.0080, MAP@30: 0.0088,\n",
            "[EPOCH: 11], Train Loss: 0.3073, Recall@30: 0.0775, Precision@30: 0.0077, MAP@30: 0.0075,\n",
            "[EPOCH: 12], Train Loss: 0.2897, Recall@30: 0.0800, Precision@30: 0.0080, MAP@30: 0.0079,\n",
            "[EPOCH: 13], Train Loss: 0.2725, Recall@30: 0.0840, Precision@30: 0.0084, MAP@30: 0.0083,\n",
            "[EPOCH: 14], Train Loss: 0.2559, Recall@30: 0.0810, Precision@30: 0.0081, MAP@30: 0.0084,\n",
            "[EPOCH: 15], Train Loss: 0.2428, Recall@30: 0.0835, Precision@30: 0.0083, MAP@30: 0.0089,\n",
            "[EPOCH: 16], Train Loss: 0.2291, Recall@30: 0.0859, Precision@30: 0.0086, MAP@30: 0.0086,\n",
            "[EPOCH: 17], Train Loss: 0.2174, Recall@30: 0.0959, Precision@30: 0.0096, MAP@30: 0.0097,\n",
            "[EPOCH: 18], Train Loss: 0.2092, Recall@30: 0.0954, Precision@30: 0.0095, MAP@30: 0.0096,\n",
            "[EPOCH: 19], Train Loss: 0.1993, Recall@30: 0.0909, Precision@30: 0.0091, MAP@30: 0.0089,\n",
            "[EPOCH: 20], Train Loss: 0.1914, Recall@30: 0.0979, Precision@30: 0.0098, MAP@30: 0.0096,\n",
            "[EPOCH: 21], Train Loss: 0.1806, Recall@30: 0.0984, Precision@30: 0.0098, MAP@30: 0.0099,\n",
            "[EPOCH: 22], Train Loss: 0.1748, Recall@30: 0.0969, Precision@30: 0.0097, MAP@30: 0.0100,\n",
            "[EPOCH: 23], Train Loss: 0.1672, Recall@30: 0.0944, Precision@30: 0.0094, MAP@30: 0.0099,\n",
            "[EPOCH: 24], Train Loss: 0.1603, Recall@30: 0.1008, Precision@30: 0.0101, MAP@30: 0.0113,\n",
            "[EPOCH: 25], Train Loss: 0.1555, Recall@30: 0.1063, Precision@30: 0.0106, MAP@30: 0.0112,\n",
            "[EPOCH: 26], Train Loss: 0.1492, Recall@30: 0.1093, Precision@30: 0.0109, MAP@30: 0.0115,\n",
            "[EPOCH: 27], Train Loss: 0.1422, Recall@30: 0.1033, Precision@30: 0.0103, MAP@30: 0.0112,\n",
            "[EPOCH: 28], Train Loss: 0.1376, Recall@30: 0.1118, Precision@30: 0.0112, MAP@30: 0.0117,\n",
            "[EPOCH: 29], Train Loss: 0.1347, Recall@30: 0.1138, Precision@30: 0.0114, MAP@30: 0.0110,\n",
            "[EPOCH: 30], Train Loss: 0.1298, Recall@30: 0.1128, Precision@30: 0.0113, MAP@30: 0.0115,\n",
            "[EPOCH: 31], Train Loss: 0.1264, Recall@30: 0.1197, Precision@30: 0.0120, MAP@30: 0.0114,\n",
            "[EPOCH: 32], Train Loss: 0.1212, Recall@30: 0.1138, Precision@30: 0.0114, MAP@30: 0.0117,\n",
            "[EPOCH: 33], Train Loss: 0.1168, Recall@30: 0.1167, Precision@30: 0.0117, MAP@30: 0.0118,\n",
            "[EPOCH: 34], Train Loss: 0.1131, Recall@30: 0.1167, Precision@30: 0.0117, MAP@30: 0.0116,\n",
            "[EPOCH: 35], Train Loss: 0.1097, Recall@30: 0.1232, Precision@30: 0.0123, MAP@30: 0.0128,\n",
            "[EPOCH: 36], Train Loss: 0.1089, Recall@30: 0.1287, Precision@30: 0.0129, MAP@30: 0.0136,\n",
            "[EPOCH: 37], Train Loss: 0.1057, Recall@30: 0.1307, Precision@30: 0.0131, MAP@30: 0.0125,\n",
            "[EPOCH: 38], Train Loss: 0.1010, Recall@30: 0.1297, Precision@30: 0.0130, MAP@30: 0.0134,\n",
            "[EPOCH: 39], Train Loss: 0.0980, Recall@30: 0.1326, Precision@30: 0.0133, MAP@30: 0.0139,\n",
            "[EPOCH: 40], Train Loss: 0.0969, Recall@30: 0.1297, Precision@30: 0.0130, MAP@30: 0.0143,\n",
            "[EPOCH: 41], Train Loss: 0.0940, Recall@30: 0.1277, Precision@30: 0.0128, MAP@30: 0.0140,\n",
            "[EPOCH: 42], Train Loss: 0.0918, Recall@30: 0.1341, Precision@30: 0.0134, MAP@30: 0.0154,\n",
            "[EPOCH: 43], Train Loss: 0.0904, Recall@30: 0.1366, Precision@30: 0.0137, MAP@30: 0.0145,\n",
            "[EPOCH: 44], Train Loss: 0.0875, Recall@30: 0.1411, Precision@30: 0.0141, MAP@30: 0.0147,\n",
            "[EPOCH: 45], Train Loss: 0.0850, Recall@30: 0.1480, Precision@30: 0.0148, MAP@30: 0.0162,\n",
            "[EPOCH: 46], Train Loss: 0.0837, Recall@30: 0.1629, Precision@30: 0.0163, MAP@30: 0.0161,\n",
            "[EPOCH: 47], Train Loss: 0.0819, Recall@30: 0.1520, Precision@30: 0.0152, MAP@30: 0.0148,\n",
            "[EPOCH: 48], Train Loss: 0.0801, Recall@30: 0.1475, Precision@30: 0.0148, MAP@30: 0.0154,\n",
            "[EPOCH: 49], Train Loss: 0.0782, Recall@30: 0.1515, Precision@30: 0.0152, MAP@30: 0.0153,\n",
            "[EPOCH: 50], Train Loss: 0.0767, Recall@30: 0.1520, Precision@30: 0.0152, MAP@30: 0.0160,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 셋이 작아서 모델의 성능이 좋은 편은 아님"
      ],
      "metadata": {
        "id": "w7_AntrGfA7O"
      }
    }
  ]
}