{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADMM-SLIM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1t2WdHmPxibGLLkm9Vf0FYaz5iwpmTrsH",
      "authorship_tag": "ABX9TyOywa0n3aOhu8bFbLZKsAy7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongBeomLEE/RecsysTutorial/blob/main/ADMM-SLIM/ADMM_SLIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-box"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzJgxsrewLBy",
        "outputId": "75d226d3-6eae-484a-eea9-b840fbd8fcf6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-box in /usr/local/lib/python3.7/dist-packages (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ug-br-pPu9vZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from box import Box\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "torch.set_printoptions(sci_mode=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbRKDSg4u9vc"
      },
      "source": [
        "# 1. 학습 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MEhK_fLIu9vd"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    'data_path' : \"/content/drive/MyDrive/RecsysTutorial/Data/MovieLens\" , # 데이터 경로\n",
        "    'valid_samples' : 10, # 검증에 사용할 sample 수\n",
        "    'seed' : 22,\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = Box(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjDxy0fJu9vf"
      },
      "source": [
        "# 2. 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W64BYWl0u9vg"
      },
      "outputs": [],
      "source": [
        "class MakeMatrixDataSet():\n",
        "    \"\"\"\n",
        "    MatrixDataSet 생성\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'ratings.csv'))\n",
        "        \n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('movieId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['movieId'].apply(lambda x : self.item_encoder[x])\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "\n",
        "        self.user_train, self.user_valid = self.generate_sequence_data()\n",
        "\n",
        "    def generate_encoder_decoder(self, col : str) -> dict:\n",
        "        \"\"\"\n",
        "        encoder, decoder 생성\n",
        "\n",
        "        Args:\n",
        "            col (str): 생성할 columns 명\n",
        "        Returns:\n",
        "            dict: 생성된 user encoder, decoder\n",
        "        \"\"\"\n",
        "\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "\n",
        "        return encoder, decoder\n",
        "    \n",
        "    def generate_sequence_data(self) -> dict:\n",
        "        \"\"\"\n",
        "        sequence_data 생성\n",
        "\n",
        "        Returns:\n",
        "            dict: train user sequence / valid user sequence\n",
        "        \"\"\"\n",
        "        users = defaultdict(list)\n",
        "        user_train = {}\n",
        "        user_valid = {}\n",
        "        for user, item, time in zip(self.df['user_idx'], self.df['item_idx'], self.df['timestamp']):\n",
        "            users[user].append(item)\n",
        "        \n",
        "        for user in users:\n",
        "            np.random.seed(self.config.seed)\n",
        "\n",
        "            user_total = users[user]\n",
        "            valid = np.random.choice(user_total, size = self.config.valid_samples, replace = False).tolist()\n",
        "            train = list(set(user_total) - set(valid))\n",
        "\n",
        "            user_train[user] = train\n",
        "            user_valid[user] = valid # valid_samples 개수 만큼 검증에 활용 (현재 Task와 가장 유사하게)\n",
        "\n",
        "        return user_train, user_valid\n",
        "    \n",
        "    def get_train_valid_data(self):\n",
        "        return self.user_train, self.user_valid\n",
        "\n",
        "    def make_matrix(self, user_list, train = True):\n",
        "        \"\"\"\n",
        "        user_item_dict를 바탕으로 행렬 생성\n",
        "        \"\"\"\n",
        "        mat = torch.zeros(size = (user_list.size(0), self.num_item))\n",
        "        for idx, user in enumerate(user_list):\n",
        "            if train:\n",
        "                mat[idx, self.user_train[user.item()]] = 1\n",
        "            else:\n",
        "                mat[idx, self.user_train[user.item()] + self.user_valid[user.item()]] = 1\n",
        "        return mat\n",
        "\n",
        "    def make_sparse_matrix(self):\n",
        "        X = sp.dok_matrix((self.num_user, self.num_item), dtype=np.float32)\n",
        "        for user in self.user_train.keys():\n",
        "            item_list = self.user_train[user]\n",
        "            X[user, item_list] = 1.0\n",
        "                \n",
        "        return X.tocsr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IldCGmY8u9vh"
      },
      "outputs": [],
      "source": [
        "class AEDataSet(Dataset):\n",
        "    def __init__(self, num_user):\n",
        "        self.num_user = num_user\n",
        "        self.users = [i for i in range(num_user)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_user\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        user = self.users[idx]\n",
        "        return torch.LongTensor([user])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysia457Su9vi"
      },
      "source": [
        "# 3. 모델"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from copy import deepcopy\n",
        "\n",
        "class AdmmSlim():\n",
        "    def __init__(self, lambda_1=10, lambda_2=5, rho=1000, positive=True, n_iter=50, eps_rel=1e-4, eps_abs=1e-3, verbose=False):\n",
        "        self.lambda_1 = lambda_1\n",
        "        self.lambda_2 = lambda_2\n",
        "        self.rho = rho\n",
        "        self.positive = positive\n",
        "        self.n_iter = n_iter\n",
        "        self.eps_rel = eps_rel\n",
        "        self.eps_abs = eps_abs\n",
        "        self.verbose = verbose\n",
        "    \n",
        "    def soft_thresholding(self, B, Gamma):\n",
        "        if self.lambda_1 == 0:\n",
        "            if self.positive:\n",
        "                return np.abs(B)\n",
        "            else:\n",
        "                return B\n",
        "        else:\n",
        "            x = B + Gamma / self.rho\n",
        "            threshold = self.lambda_1 / self.rho\n",
        "            if self.positive:\n",
        "                return np.where(threshold < x, x - threshold, 0)\n",
        "            else:\n",
        "                return np.where(threshold < x, x - threshold,\n",
        "                                np.where(x < - threshold, x + threshold, 0))\n",
        "\n",
        "    def is_converged(self, B, C, C_old, Gamma):\n",
        "        B_norm = np.linalg.norm(B)\n",
        "        C_norm = np.linalg.norm(C)\n",
        "        Gamma_norm = np.linalg.norm(Gamma)\n",
        "\n",
        "        eps_primal = self.eps_abs * B.shape[0] - self.eps_rel * np.max([B_norm, C_norm])\n",
        "        eps_dual = self.eps_abs * B.shape[0] - self.eps_rel * Gamma_norm\n",
        "\n",
        "        R_primal_norm = np.linalg.norm(B - C)\n",
        "        R_dual_norm = np.linalg.norm(C  - C_old) * self.rho\n",
        "\n",
        "        converged = R_primal_norm < eps_primal and R_dual_norm < eps_dual\n",
        "        return converged\n",
        "\n",
        "    def fit(self, X):\n",
        "        XtX = X.T.dot(X)\n",
        "        if sparse.issparse(XtX):\n",
        "            XtX = XtX.todense().A\n",
        "\n",
        "        if self.verbose:\n",
        "            print(' --- init')\n",
        "        identity_mat = np.identity(XtX.shape[0])\n",
        "        diags = identity_mat * (self.lambda_2 + self.rho)\n",
        "        P = np.linalg.inv(XtX + diags).astype(np.float32)\n",
        "        B_aux = P.dot(XtX)\n",
        "\n",
        "        Gamma = np.zeros_like(XtX, dtype=np.float32)\n",
        "        C = np.zeros_like(XtX, dtype=np.float32)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(' --- iteration start.')\n",
        "        for iter in range(self.n_iter):\n",
        "            if self.verbose:\n",
        "                print(f' --- iteration {iter+1}/{self.n_iter}')\n",
        "            C_old = C.copy()\n",
        "            B_tilde = B_aux + P.dot(self.rho * C - Gamma)\n",
        "            gamma = np.diag(B_tilde) / (np.diag(P) + 1e-8)\n",
        "            B = B_tilde - P * gamma\n",
        "            C = self.soft_thresholding(B, Gamma)\n",
        "            Gamma = Gamma + self.rho * (B - C)\n",
        "            if self.is_converged(B, C, C_old, Gamma):\n",
        "                if self.verbose:\n",
        "                    print(f' --- Converged. Stopped iteration.')\n",
        "                break\n",
        "\n",
        "        coef = C\n",
        "\n",
        "        self.pred = torch.from_numpy(X.dot(coef))"
      ],
      "metadata": {
        "id": "TVXWUTLpSh8_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwSexh43u9vk"
      },
      "source": [
        "# 4. 학습 함수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ndcg(pred_list, true_list):\n",
        "    idcg = sum((1 / np.log2(rank + 2) for rank in range(1, len(pred_list))))\n",
        "    dcg = 0\n",
        "    for rank, pred in enumerate(pred_list):\n",
        "        if pred in true_list:\n",
        "            dcg += 1 / np.log2(rank + 2)\n",
        "    ndcg = dcg / idcg\n",
        "    return ndcg\n",
        "\n",
        "# hit == recall == precision\n",
        "def get_hit(pred_list, true_list):\n",
        "    hit_list = set(true_list) & set(pred_list)\n",
        "    hit = len(hit_list) / len(true_list)\n",
        "    return hit\n",
        "\n",
        "def evaluate(model, X, user_train, user_valid):\n",
        "\n",
        "    mat = torch.from_numpy(X)\n",
        "\n",
        "    NDCG = 0.0 # NDCG@10\n",
        "    HIT = 0.0 # HIT@10\n",
        "\n",
        "    recon_mat1 = model.pred.cpu()\n",
        "    recon_mat1[mat == 1] = -np.inf\n",
        "    rec_list1 = recon_mat1.argsort(dim = 1)\n",
        "\n",
        "    for user, rec1 in tqdm(enumerate(rec_list1)):\n",
        "        uv = user_valid[user]\n",
        "\n",
        "        # ranking\n",
        "        up = rec1[-10:].cpu().numpy().tolist()[::-1]\n",
        "\n",
        "        NDCG += get_ndcg(pred_list = up, true_list = uv)\n",
        "        HIT += get_hit(pred_list = up, true_list = uv)\n",
        "\n",
        "    NDCG /= len(user_train)\n",
        "    HIT /= len(user_train)\n",
        "\n",
        "    return NDCG, HIT"
      ],
      "metadata": {
        "id": "nws4JO2_rgQP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 학습"
      ],
      "metadata": {
        "id": "gupkaJHMslCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_matrix_data_set = MakeMatrixDataSet(config = config)\n",
        "user_train, user_valid = make_matrix_data_set.get_train_valid_data()\n",
        "X = make_matrix_data_set.make_sparse_matrix()"
      ],
      "metadata": {
        "id": "HFOr6Wmbq9pW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AdmmSlim(n_iter=10)\n",
        "model.fit(X = X)\n",
        "ndcg, hit = evaluate(model = model, X = X.todense(), user_train = user_train, user_valid = user_valid)\n",
        "print(f'NDCG@10: {ndcg:.5f}| HIT@10: {hit:.5f}')"
      ],
      "metadata": {
        "id": "mzhvIGPhrYov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46419bf4-faa4-4adc-9b8a-5912f0b61d01"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "671it [00:00, 28334.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG@10: 0.24667| HIT@10: 0.16289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}