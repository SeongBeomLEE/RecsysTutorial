{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Collaborative_Filtering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fn_ia2LJlHdMS4VmV68F_aMvkpKjxy-N",
      "authorship_tag": "ABX9TyPRJChifYJ/YGv2JMOM+G9f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongBeomLEE/RecsysTutorial/blob/main/NCF/Neural_Collaborative_Filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 구현 내용\n",
        "\n",
        "- 데이터셋 분리\n",
        "- 우선 전체 데이터셋으로 positive 셋과 negative 셋을 구하자\n",
        "- 학습용 데이터 셋 <- 모든 데어터가 다 1, 이후에 네거티브 샘플링이 추가됨\n",
        "- 테스트용 데이터 셋 <- 제일 첫번째만 1(제일 마지막 시청 기록으로 사용) 나머지는 다 0(네가티브 셋에서 99개 샘플링)\n",
        "\n",
        "\n",
        "- 모델 설정\n",
        "- GMF - adam / embedding은 정규 분포에서 초기화, 표준편차 0.01 / Layer=64,1 / bias - False,\n",
        "- MLP - adam / embedding은 정규 분포에서 초기화, 표준편차 0.01 / Layer=128,64,32,1 / bias = True,\n",
        "- NeuMF - SGD / GMF와 MLP의 pretrain된 파라미터로 구성된 모델 / GMF + MLP(64), 1 / bias - False,\n",
        "\n",
        "\n",
        "- 메트릭 설정\n",
        "- NDCG@K, HR@K\n",
        "- NDCG@K의 경우 top_k에 안에 정답 셋이 몇번째 idx에 존재하는 지 판단하여 그 값으로 계산 (추후에 평균을 냄)\n",
        "- HR@K의 경우 top_k에 안에 정답 셋이 존재하면 1을 반환 (추후에 평균을 냄)"
      ],
      "metadata": {
        "id": "ZtQHaFTTJ5Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/RecsysTutorial/Data/MovieLens/'\n",
        "model_dir = '/content/drive/MyDrive/RecsysTutorial/Model/'"
      ],
      "metadata": {
        "id": "bH1-lJmSOqfR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 확인"
      ],
      "metadata": {
        "id": "dLHonyUm5x51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df = pd.read_csv(data_dir + 'ratings.csv')\n",
        "ratings_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "xHXEweQq5Xfu",
        "outputId": "63e0c1d0-10db-4234-b5ae-15daca1c3fb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b2815e33-e618-4ff1-b29e-9105e8fa6b99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1260759144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1029</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1260759179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1061</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1260759182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1129</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1172</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1260759205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1263</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1287</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1293</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1339</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1260759125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1343</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1260759131</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2815e33-e618-4ff1-b29e-9105e8fa6b99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2815e33-e618-4ff1-b29e-9105e8fa6b99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2815e33-e618-4ff1-b29e-9105e8fa6b99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1       31     2.5  1260759144\n",
              "1       1     1029     3.0  1260759179\n",
              "2       1     1061     3.0  1260759182\n",
              "3       1     1129     2.0  1260759185\n",
              "4       1     1172     4.0  1260759205\n",
              "5       1     1263     2.0  1260759151\n",
              "6       1     1287     2.0  1260759187\n",
              "7       1     1293     2.0  1260759148\n",
              "8       1     1339     3.5  1260759125\n",
              "9       1     1343     2.0  1260759131"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_user = ratings_df['userId'].nunique()\n",
        "num_item = ratings_df['movieId'].nunique()\n",
        "\n",
        "sparsity = 1 - len(ratings_df) / (num_user * num_item)\n",
        "\n",
        "print(f'전체 User 수: {num_user}')\n",
        "print(f'전체 Item 수: {num_item}')\n",
        "print(f'행렬의 희소성: {sparsity:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KKZeIWg6iSp",
        "outputId": "2948b561-1433-41a2-9b65-b28d7b831933"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 User 수: 671\n",
            "전체 Item 수: 9066\n",
            "행렬의 희소성: 0.9836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.histplot(ratings_df['rating'])\n",
        "plt.title('Rating distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "DzYlEJQb64WL",
        "outputId": "8abfbc9f-ff01-4551-83e2-f2d688079f14"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Rating distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 제작"
      ],
      "metadata": {
        "id": "nfr9ZtE35ze_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_encoder, user_decoder = {}, {}\n",
        "for idx, user_id in enumerate(ratings_df['userId'].unique()):\n",
        "    user_encoder[user_id] = idx\n",
        "    user_decoder[idx] = user_id\n",
        "\n",
        "item_encoder, item_decoder = {}, {}\n",
        "for idx, item_id in enumerate(ratings_df['movieId'].unique()):\n",
        "    item_encoder[item_id] = idx\n",
        "    item_decoder[idx] = item_id"
      ],
      "metadata": {
        "id": "nT-5QIEzRyYH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df['en_userId'] = ratings_df['userId'].apply(lambda x : user_encoder[x])\n",
        "ratings_df['en_movieId'] = ratings_df['movieId'].apply(lambda x : item_encoder[x])"
      ],
      "metadata": {
        "id": "aUiCkIn0PtI2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 논문에서 제공된 깃허브의 데이터를 보면\n",
        "# test 데이터셋이 100개의 데이터 중 첫번째 데이터를 제외한 나머지 99개 데이터는 모두 neg 데이터라고 함\n",
        "# 따라서 이에 맞춰서 데이터를 나눔\n",
        "\n",
        "def split_data(df, num_neg = 2):\n",
        "    total_item_li = set([i for i in range(num_item)])\n",
        "    train_df = []\n",
        "    test_df = []\n",
        "    en_user_id_li = df['en_userId'].unique()\n",
        "    for en_user_id in tqdm(en_user_id_li):\n",
        "        pos_recomencder_li = df[df['en_userId'] == en_user_id]['en_movieId'].tolist()\n",
        "        neg_recomencder_li = np.random.choice(list(total_item_li - set(pos_recomencder_li)), num_neg * len(pos_recomencder_li), replace = False).tolist()\n",
        "        train_df += [[en_user_id, en_movieId, 1] for en_movieId in pos_recomencder_li[:-1]] + [[en_user_id, en_movieId, 0] for en_movieId in neg_recomencder_li]\n",
        "\n",
        "        neg_recomencder_li = np.random.choice(list(total_item_li - set(pos_recomencder_li)), 99, replace = False).tolist()\n",
        "        test_df += [[en_user_id, pos_recomencder_li[-1], 1]] + [[en_user_id, en_movieId, 0] for en_movieId in neg_recomencder_li]\n",
        "    \n",
        "    return train_df, test_df"
      ],
      "metadata": {
        "id": "VRdQ8W9aSFIu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user = self.df[idx][0]\n",
        "        item = self.df[idx][1]\n",
        "        label = self.df[idx][2]\n",
        "\n",
        "        return user, item, label"
      ],
      "metadata": {
        "id": "qe-XstHsX9Ox"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GMF"
      ],
      "metadata": {
        "id": "uQJURH87i5KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GMF(nn.Module):\n",
        "    def __init__(self, num_user, num_item, num_factor):\n",
        "        super(GMF, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_user, num_factor)\n",
        "        self.item_emb = nn.Embedding(num_item, num_factor)\n",
        "        \n",
        "        self.predict_layer = nn.Sequential(\n",
        "            nn.Linear(num_factor, 1, bias = False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self._init_weight_()\n",
        "    \n",
        "    def _init_weight_(self):\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
        "        for m in self.predict_layer:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
        "    \n",
        "    def forward(self, user, item):\n",
        "        user_emb = self.user_emb(user)\n",
        "        item_emb = self.item_emb(item)\n",
        "\n",
        "        output = self.predict_layer(user_emb * item_emb)\n",
        "\n",
        "        return output.view(-1)"
      ],
      "metadata": {
        "id": "6cH6SL6ahWFB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "lh0xT05Vi6s2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, num_user, num_item, num_factor, num_layers, dropout):\n",
        "        super(MLP, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.user_emb = nn.Embedding(num_user, num_factor)\n",
        "        self.item_emb = nn.Embedding(num_item, num_factor)\n",
        "\n",
        "        MLP_modules = []\n",
        "        input_size = num_factor * 2\n",
        "        for i in range(num_layers):\n",
        "            MLP_modules.append(nn.Dropout(p = self.dropout))\n",
        "            MLP_modules.append(nn.Linear(input_size, input_size // 2))\n",
        "            MLP_modules.append(nn.ReLU())\n",
        "            input_size = input_size // 2\n",
        "        self.MLP_layers = nn.Sequential(*MLP_modules)\n",
        "\n",
        "        self.predict_layer = nn.Sequential(\n",
        "            nn.Linear(input_size, 1, bias = False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self._init_weight_()\n",
        "    \n",
        "    def _init_weight_(self):\n",
        "        nn.init.normal_(self.user_emb.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_emb.weight, std=0.01)\n",
        "        for m in self.MLP_layers:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "        \n",
        "        for m in self.predict_layer:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
        "    \n",
        "    def forward(self, user, item):\n",
        "        user_emb = self.user_emb(user)\n",
        "        item_emb = self.item_emb(item)\n",
        "        \n",
        "        cat_emb = torch.cat((user_emb, item_emb), -1)\n",
        "\n",
        "        output = self.MLP_layers(cat_emb)\n",
        "\n",
        "        output = self.predict_layer(output)\n",
        "\n",
        "        return output.view(-1)"
      ],
      "metadata": {
        "id": "L0GBdNzFi73i"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NeuMF"
      ],
      "metadata": {
        "id": "PEhpOK85i8Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuMF(nn.Module):\n",
        "    def __init__(self, GMF, MLP, num_factor):\n",
        "        super(NeuMF, self).__init__()\n",
        "        self.gmf_user_emb = GMF.user_emb\n",
        "        self.gmf_item_emb = GMF.item_emb\n",
        "\n",
        "        self.mlp_user_emb = MLP.user_emb\n",
        "        self.mlp_item_emb = MLP.item_emb\n",
        "\n",
        "        self.mlp_layer = MLP.MLP_layers\n",
        "\n",
        "        self.predict_layer = nn.Sequential(\n",
        "            nn.Linear(num_factor + (num_factor // 2), 1, bias = False),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self._init_weight_()\n",
        "    \n",
        "    def _init_weight_(self):\n",
        "        for m in self.predict_layer:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight, a=1, nonlinearity=\"sigmoid\")\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        gmf_user_emb = self.gmf_user_emb(user)\n",
        "        gmf_item_emb = self.gmf_item_emb(item)\n",
        "        gmf_output = gmf_user_emb * gmf_item_emb\n",
        "\n",
        "        mlp_user_emb = self.mlp_user_emb(user)\n",
        "        mlp_item_emb = self.mlp_item_emb(item)\n",
        "        mlp_cat_emb = torch.cat((mlp_user_emb, mlp_item_emb), -1)\n",
        "        mlp_output = self.mlp_layer(mlp_cat_emb)\n",
        "        \n",
        "        cat_output = torch.cat((gmf_output, mlp_output), -1)\n",
        "\n",
        "        output = self.predict_layer(cat_output)\n",
        "\n",
        "        return output.view(-1)"
      ],
      "metadata": {
        "id": "SR5ABy5Hi9kG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 설정"
      ],
      "metadata": {
        "id": "zBtWNtJ8i95I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hit(target_item, pred_items):\n",
        "    if target_item in pred_items:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def ndcg(target_item, pred_items):\n",
        "    if target_item in pred_items:\n",
        "        idx = pred_items.index(target_item)\n",
        "        # 초기 인덱스가 0이기 때문에 +2 함\n",
        "        return np.reciprocal(np.log2(idx + 2))\n",
        "    return 0\n",
        "\n",
        "def metrics(model, test_loader, top_k):\n",
        "    model.eval()\n",
        "    HR, NDCG = [], []\n",
        "    with torch.no_grad():\n",
        "        for user, item, _ in test_loader:\n",
        "            user = user.to(device)\n",
        "            item = item.to(device)\n",
        "\n",
        "            predictions = model(user, item)\n",
        "            # 가장 높은 top_k개 선택\n",
        "            _, indices = torch.topk(predictions, top_k)\n",
        "            # 해당 상품 index 선택\n",
        "            recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
        "            # 정답값 선택\n",
        "            target_item = item[0].item()\n",
        "            HR.append(hit(target_item, recommends))\n",
        "            NDCG.append(ndcg(target_item, recommends))\n",
        "\n",
        "    return np.mean(HR), np.mean(NDCG)\n",
        "    \n",
        "def train(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    for user, item, label in train_loader:\n",
        "        user = user.to(device)\n",
        "        item = item.to(device)\n",
        "        label = label.to(device)\n",
        "        label = label.float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(user, item)\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "Y50-oJ51pGKi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "batch_size = 256\n",
        "epochs = 30\n",
        "lr = 0.005\n",
        "num_factor = 64\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "top_k = 30\n",
        "num_neg = 2"
      ],
      "metadata": {
        "id": "JW5V8S09nsqU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = split_data(df = ratings_df, num_neg = num_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz_77KOwQqPu",
        "outputId": "d2f48b4a-55a2-48b1-e47c-9c93b0f67307"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 671/671 [00:02<00:00, 265.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(df = train_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, drop_last = False)\n",
        "\n",
        "test_dataset = CustomDataset(df = test_df)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 100, shuffle = False, drop_last = False)"
      ],
      "metadata": {
        "id": "z3lvY0gkfpQK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GMF + MLP 학습"
      ],
      "metadata": {
        "id": "6OKGP1GBjAxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
        "gmf_optimizer = torch.optim.Adam(gmf.parameters(), lr = lr)\n",
        "\n",
        "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
        "mlp_optimizer = torch.optim.Adam(mlp.parameters(), lr = lr)\n",
        "\n",
        "loss_fc = nn.BCELoss()"
      ],
      "metadata": {
        "id": "76tZOKFdjFwE"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gmf_best_metric = 0\n",
        "mlp_best_metric = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    gmf_train_loss = train(model = gmf, train_loader = train_loader, criterion = loss_fc, optimizer = gmf_optimizer)\n",
        "    gmf_hr, gmf_ndcg = metrics(model = gmf, test_loader = test_loader, top_k = top_k)\n",
        "\n",
        "    mlp_train_loss = train(model = mlp, train_loader = train_loader, criterion = loss_fc, optimizer = mlp_optimizer)\n",
        "    mlp_hr, mlp_ndcg  = metrics(model = mlp, test_loader = test_loader, top_k = top_k)\n",
        "\n",
        "    print(f\"[EPOCH: {epoch}], GMF Train Loss: {gmf_train_loss:.4f}, MLP Train Loss: {mlp_train_loss:.4f}, GMF HR: {gmf_hr:.4f}, MLP HR: {mlp_hr:.4f}, GMF NDCG: {gmf_ndcg:.4f}, MLP NDCG: {mlp_ndcg:.4f}\")\n",
        "\n",
        "    if gmf_best_metric < gmf_ndcg:\n",
        "        gmf_best_metric = gmf_ndcg\n",
        "        torch.save(gmf.state_dict(), model_dir + f'GMF.pt')\n",
        "\n",
        "    if mlp_best_metric < mlp_ndcg:\n",
        "        mlp_best_metric = mlp_ndcg\n",
        "        torch.save(mlp.state_dict(), model_dir + f'MLP.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glaTED4VxIz2",
        "outputId": "f979b0de-8cb1-4cd7-cd5a-88fde5629605"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH: 1], GMF Train Loss: 0.4643, MLP Train Loss: 0.4429, GMF HR: 0.7839, MLP HR: 0.7168, GMF NDCG: 0.3553, MLP NDCG: 0.3121\n",
            "[EPOCH: 2], GMF Train Loss: 0.2635, MLP Train Loss: 0.4029, GMF HR: 0.7750, MLP HR: 0.7243, GMF NDCG: 0.3673, MLP NDCG: 0.3204\n",
            "[EPOCH: 3], GMF Train Loss: 0.0832, MLP Train Loss: 0.3828, GMF HR: 0.7779, MLP HR: 0.7392, GMF NDCG: 0.3557, MLP NDCG: 0.3304\n",
            "[EPOCH: 4], GMF Train Loss: 0.0220, MLP Train Loss: 0.3540, GMF HR: 0.7705, MLP HR: 0.7437, GMF NDCG: 0.3621, MLP NDCG: 0.3465\n",
            "[EPOCH: 5], GMF Train Loss: 0.0055, MLP Train Loss: 0.3297, GMF HR: 0.7675, MLP HR: 0.7750, GMF NDCG: 0.3582, MLP NDCG: 0.3678\n",
            "[EPOCH: 6], GMF Train Loss: 0.0014, MLP Train Loss: 0.3127, GMF HR: 0.7675, MLP HR: 0.7779, GMF NDCG: 0.3560, MLP NDCG: 0.3776\n",
            "[EPOCH: 7], GMF Train Loss: 0.0004, MLP Train Loss: 0.2995, GMF HR: 0.7705, MLP HR: 0.7675, GMF NDCG: 0.3576, MLP NDCG: 0.3724\n",
            "[EPOCH: 8], GMF Train Loss: 0.0002, MLP Train Loss: 0.2879, GMF HR: 0.7705, MLP HR: 0.7735, GMF NDCG: 0.3582, MLP NDCG: 0.3886\n",
            "[EPOCH: 9], GMF Train Loss: 0.0001, MLP Train Loss: 0.2782, GMF HR: 0.7735, MLP HR: 0.7660, GMF NDCG: 0.3569, MLP NDCG: 0.3689\n",
            "[EPOCH: 10], GMF Train Loss: 0.0000, MLP Train Loss: 0.2694, GMF HR: 0.7705, MLP HR: 0.7586, GMF NDCG: 0.3544, MLP NDCG: 0.3604\n",
            "[EPOCH: 11], GMF Train Loss: 0.0000, MLP Train Loss: 0.2615, GMF HR: 0.7690, MLP HR: 0.7586, GMF NDCG: 0.3530, MLP NDCG: 0.3758\n",
            "[EPOCH: 12], GMF Train Loss: 0.0000, MLP Train Loss: 0.2553, GMF HR: 0.7675, MLP HR: 0.7735, GMF NDCG: 0.3501, MLP NDCG: 0.3835\n",
            "[EPOCH: 13], GMF Train Loss: 0.0000, MLP Train Loss: 0.2495, GMF HR: 0.7690, MLP HR: 0.7705, GMF NDCG: 0.3481, MLP NDCG: 0.3796\n",
            "[EPOCH: 14], GMF Train Loss: 0.0000, MLP Train Loss: 0.2453, GMF HR: 0.7630, MLP HR: 0.7809, GMF NDCG: 0.3438, MLP NDCG: 0.3892\n",
            "[EPOCH: 15], GMF Train Loss: 0.0000, MLP Train Loss: 0.2391, GMF HR: 0.7601, MLP HR: 0.7943, GMF NDCG: 0.3400, MLP NDCG: 0.3807\n",
            "[EPOCH: 16], GMF Train Loss: 0.0000, MLP Train Loss: 0.2351, GMF HR: 0.7586, MLP HR: 0.7854, GMF NDCG: 0.3380, MLP NDCG: 0.3746\n",
            "[EPOCH: 17], GMF Train Loss: 0.0000, MLP Train Loss: 0.2320, GMF HR: 0.7601, MLP HR: 0.7943, GMF NDCG: 0.3383, MLP NDCG: 0.3824\n",
            "[EPOCH: 18], GMF Train Loss: 0.0000, MLP Train Loss: 0.2287, GMF HR: 0.7586, MLP HR: 0.7988, GMF NDCG: 0.3348, MLP NDCG: 0.3914\n",
            "[EPOCH: 19], GMF Train Loss: 0.0000, MLP Train Loss: 0.2239, GMF HR: 0.7586, MLP HR: 0.7914, GMF NDCG: 0.3327, MLP NDCG: 0.3802\n",
            "[EPOCH: 20], GMF Train Loss: 0.0000, MLP Train Loss: 0.2224, GMF HR: 0.7601, MLP HR: 0.7839, GMF NDCG: 0.3294, MLP NDCG: 0.3749\n",
            "[EPOCH: 21], GMF Train Loss: 0.0000, MLP Train Loss: 0.2189, GMF HR: 0.7586, MLP HR: 0.7794, GMF NDCG: 0.3288, MLP NDCG: 0.3691\n",
            "[EPOCH: 22], GMF Train Loss: 0.0000, MLP Train Loss: 0.2172, GMF HR: 0.7586, MLP HR: 0.7854, GMF NDCG: 0.3265, MLP NDCG: 0.3672\n",
            "[EPOCH: 23], GMF Train Loss: 0.0000, MLP Train Loss: 0.2145, GMF HR: 0.7601, MLP HR: 0.7899, GMF NDCG: 0.3252, MLP NDCG: 0.3738\n",
            "[EPOCH: 24], GMF Train Loss: 0.0000, MLP Train Loss: 0.2121, GMF HR: 0.7601, MLP HR: 0.7884, GMF NDCG: 0.3229, MLP NDCG: 0.3911\n",
            "[EPOCH: 25], GMF Train Loss: 0.0000, MLP Train Loss: 0.2095, GMF HR: 0.7601, MLP HR: 0.7899, GMF NDCG: 0.3219, MLP NDCG: 0.3910\n",
            "[EPOCH: 26], GMF Train Loss: 0.0000, MLP Train Loss: 0.2066, GMF HR: 0.7571, MLP HR: 0.7794, GMF NDCG: 0.3218, MLP NDCG: 0.3810\n",
            "[EPOCH: 27], GMF Train Loss: 0.0000, MLP Train Loss: 0.2061, GMF HR: 0.7571, MLP HR: 0.7809, GMF NDCG: 0.3213, MLP NDCG: 0.3635\n",
            "[EPOCH: 28], GMF Train Loss: 0.0000, MLP Train Loss: 0.2047, GMF HR: 0.7556, MLP HR: 0.8033, GMF NDCG: 0.3205, MLP NDCG: 0.3747\n",
            "[EPOCH: 29], GMF Train Loss: 0.0000, MLP Train Loss: 0.2034, GMF HR: 0.7556, MLP HR: 0.7928, GMF NDCG: 0.3204, MLP NDCG: 0.3727\n",
            "[EPOCH: 30], GMF Train Loss: 0.0000, MLP Train Loss: 0.2013, GMF HR: 0.7556, MLP HR: 0.7928, GMF NDCG: 0.3197, MLP NDCG: 0.3721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NeuMF 학습"
      ],
      "metadata": {
        "id": "DwyFTLcXjFcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NeuMF 의 경우 pre-trained 모델을 사용한다고 함\n",
        "# 그리고 optimizer로 SGD를 사용한다고 함\n",
        "# 실제로 Adam 보다 더 좋은 성능을 보임\n",
        "\n",
        "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
        "gmf.load_state_dict(torch.load(model_dir + f'GMF.pt'))\n",
        "\n",
        "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
        "mlp.load_state_dict(torch.load(model_dir + f'MLP.pt'))\n",
        "\n",
        "nmf = NeuMF(GMF = gmf, MLP = mlp, num_factor = num_factor).to(device)\n",
        "nmf_optimizer = torch.optim.SGD(nmf.parameters(), lr = lr, momentum = 0.9)"
      ],
      "metadata": {
        "id": "gW_htbrTohKs"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nmf_best_metric = 0\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    nmf_train_loss = train(model = nmf, train_loader = train_loader, criterion = loss_fc, optimizer = nmf_optimizer)\n",
        "    nmf_hr, nmf_ndcg = metrics(model = nmf, test_loader = test_loader, top_k = top_k)\n",
        "\n",
        "    print(f\"[EPOCH: {epoch}], NeuMF Train Loss: {nmf_train_loss:.4f}, NeuMF HR: {nmf_hr:.4f}, NeuMF NDCG: {nmf_ndcg:.4f}\")\n",
        "\n",
        "    if nmf_best_metric < nmf_ndcg:\n",
        "        nmf_best_metric = nmf_ndcg\n",
        "        torch.save(nmf.state_dict(), model_dir + f'NeuMF.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG_76D0fz7_8",
        "outputId": "8842cdd7-c9ef-4da1-cce5-54241e606e53"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH: 1], NeuMF Train Loss: 0.2048, NeuMF HR: 0.7943, NeuMF NDCG: 0.3862\n",
            "[EPOCH: 2], NeuMF Train Loss: 0.1696, NeuMF HR: 0.7958, NeuMF NDCG: 0.3878\n",
            "[EPOCH: 3], NeuMF Train Loss: 0.1520, NeuMF HR: 0.7928, NeuMF NDCG: 0.3911\n",
            "[EPOCH: 4], NeuMF Train Loss: 0.1378, NeuMF HR: 0.7988, NeuMF NDCG: 0.3913\n",
            "[EPOCH: 5], NeuMF Train Loss: 0.1274, NeuMF HR: 0.7988, NeuMF NDCG: 0.3929\n",
            "[EPOCH: 6], NeuMF Train Loss: 0.1185, NeuMF HR: 0.7988, NeuMF NDCG: 0.3914\n",
            "[EPOCH: 7], NeuMF Train Loss: 0.1110, NeuMF HR: 0.8003, NeuMF NDCG: 0.3953\n",
            "[EPOCH: 8], NeuMF Train Loss: 0.1054, NeuMF HR: 0.8018, NeuMF NDCG: 0.3929\n",
            "[EPOCH: 9], NeuMF Train Loss: 0.1001, NeuMF HR: 0.8018, NeuMF NDCG: 0.3935\n",
            "[EPOCH: 10], NeuMF Train Loss: 0.0962, NeuMF HR: 0.8033, NeuMF NDCG: 0.3963\n",
            "[EPOCH: 11], NeuMF Train Loss: 0.0921, NeuMF HR: 0.8018, NeuMF NDCG: 0.3902\n",
            "[EPOCH: 12], NeuMF Train Loss: 0.0890, NeuMF HR: 0.7973, NeuMF NDCG: 0.3902\n",
            "[EPOCH: 13], NeuMF Train Loss: 0.0862, NeuMF HR: 0.7988, NeuMF NDCG: 0.3899\n",
            "[EPOCH: 14], NeuMF Train Loss: 0.0837, NeuMF HR: 0.8003, NeuMF NDCG: 0.3904\n",
            "[EPOCH: 15], NeuMF Train Loss: 0.0810, NeuMF HR: 0.8003, NeuMF NDCG: 0.3901\n",
            "[EPOCH: 16], NeuMF Train Loss: 0.0791, NeuMF HR: 0.8018, NeuMF NDCG: 0.3921\n",
            "[EPOCH: 17], NeuMF Train Loss: 0.0773, NeuMF HR: 0.8033, NeuMF NDCG: 0.3921\n",
            "[EPOCH: 18], NeuMF Train Loss: 0.0755, NeuMF HR: 0.8018, NeuMF NDCG: 0.3922\n",
            "[EPOCH: 19], NeuMF Train Loss: 0.0739, NeuMF HR: 0.8018, NeuMF NDCG: 0.3898\n",
            "[EPOCH: 20], NeuMF Train Loss: 0.0726, NeuMF HR: 0.8003, NeuMF NDCG: 0.3905\n",
            "[EPOCH: 21], NeuMF Train Loss: 0.0708, NeuMF HR: 0.8003, NeuMF NDCG: 0.3903\n",
            "[EPOCH: 22], NeuMF Train Loss: 0.0698, NeuMF HR: 0.7973, NeuMF NDCG: 0.3869\n",
            "[EPOCH: 23], NeuMF Train Loss: 0.0685, NeuMF HR: 0.8018, NeuMF NDCG: 0.3919\n",
            "[EPOCH: 24], NeuMF Train Loss: 0.0674, NeuMF HR: 0.8018, NeuMF NDCG: 0.3925\n",
            "[EPOCH: 25], NeuMF Train Loss: 0.0662, NeuMF HR: 0.7988, NeuMF NDCG: 0.3882\n",
            "[EPOCH: 26], NeuMF Train Loss: 0.0655, NeuMF HR: 0.7988, NeuMF NDCG: 0.3890\n",
            "[EPOCH: 27], NeuMF Train Loss: 0.0644, NeuMF HR: 0.7958, NeuMF NDCG: 0.3892\n",
            "[EPOCH: 28], NeuMF Train Loss: 0.0634, NeuMF HR: 0.7988, NeuMF NDCG: 0.3902\n",
            "[EPOCH: 29], NeuMF Train Loss: 0.0626, NeuMF HR: 0.7973, NeuMF NDCG: 0.3887\n",
            "[EPOCH: 30], NeuMF Train Loss: 0.0615, NeuMF HR: 0.7973, NeuMF NDCG: 0.3848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 평가"
      ],
      "metadata": {
        "id": "HSFXb3psjJFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nmf = NeuMF(GMF = gmf, MLP = mlp, num_factor = num_factor).to(device)\n",
        "nmf.load_state_dict(torch.load(model_dir + f'NeuMF.pt'))\n",
        "\n",
        "gmf = GMF(num_user = num_user, num_item = num_item, num_factor = num_factor).to(device)\n",
        "gmf.load_state_dict(torch.load(model_dir + f'GMF.pt'))\n",
        "\n",
        "mlp = MLP(num_user = num_user, num_item = num_item, num_factor = num_factor, num_layers = num_layers, dropout = dropout).to(device)\n",
        "mlp.load_state_dict(torch.load(model_dir + f'MLP.pt'))\n",
        "\n",
        "gmf_hr, gmf_ndcg = metrics(model = gmf, test_loader = test_loader, top_k = top_k)\n",
        "mlp_hr, mlp_ndcg  = metrics(model = mlp, test_loader = test_loader, top_k = top_k)\n",
        "nmf_hr, nmf_ndcg = metrics(model = nmf, test_loader = test_loader, top_k = top_k)\n",
        "\n",
        "print(f\"NeuMF HR: {nmf_hr:.4f}, NeuMF NDCG: {nmf_ndcg:.4f}, \\n MLP HR: {mlp_hr:.4f}, MLP NDCG: {mlp_ndcg:.4f} \\n GMF HR: {gmf_hr:.4f}, GMF NDCG: {gmf_ndcg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkEMePXajKIM",
        "outputId": "d62039e5-860f-4e8f-fafd-7107bec7f292"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuMF HR: 0.8033, NeuMF NDCG: 0.3963, \n",
            " MLP HR: 0.7988, MLP NDCG: 0.3914 \n",
            " GMF HR: 0.7750, GMF NDCG: 0.3673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NeuMF > MLP > GMF 순으로 모델의 성능이 우수함, 논문 보다 적은 수의 데이터 셋을 사용하였지만 논문과 비슷한 수준의 성능이 재현됨"
      ],
      "metadata": {
        "id": "mYI8TtaK_Jon"
      }
    }
  ]
}